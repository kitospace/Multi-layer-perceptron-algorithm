{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59f19490",
   "metadata": {},
   "source": [
    "# Perceptron Learning Algorithm\n",
    "\n",
    "- It is the type of Neural Network model, perheps the simplest type of neural network model. \n",
    "\n",
    "- It consists of single node and neuron that takes a row of data as inputs and predicts a class label. \n",
    "\n",
    "- This is achieved by calculating the the weighted sum of inputs and a bias(set of 1). \n",
    "\n",
    "- There we use the linear regression activation function. \n",
    "\n",
    "- That look like : (weights*inputs) + bias\n",
    "\n",
    "- Predictions works like : 1. Predict 1 -> if activation>0.0\n",
    "                         ||  2. Predict 0 -> if activation<=0.0\n",
    "                           \n",
    "- The Perceptron is a linear classification algorithm. This means that it learns a decision boundary that separates two classes using a line (called a hyperplane) in the feature space. \n",
    "\n",
    "- Weights(Coeffients) are trained using Stochestic Gradient Descent.\n",
    "\n",
    "- Examples from the training dataset are shown to the model one at a time, the model makes a prediction, and error is calculated.\n",
    "\n",
    "- The weights of the model are then updated to reduce the errors for the example. **This is called the Perceptron update rule.**\n",
    "\n",
    "-  This process is repeated for all examples in the training dataset, called an **epoch.**\n",
    "\n",
    "- Model weights are updated with a small proportion of the error each batch, and the proportion is controlled by a hyperparameter called the **learning rate**, typically set to a small value.\n",
    "\n",
    "- This is to ensure learning does not occur too quickly, resulting in a possibly lower skill model, referred to as premature convergence of the optimization (search) procedure for the model weights.\n",
    "\n",
    "- weights(t + 1) = weights(t) + learning_rate * (expected_i – predicted_) * input_i\n",
    "\n",
    "\n",
    "`credits: https://machinelearningmastery.com/perceptron-algorithm-for-classification-in-python/#:~:text=The%20Perceptron%20is%20a%20linear%20classification%20algorithm.,hyperplane)%20in%20the%20feature%20space.`\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deddb4f5",
   "metadata": {},
   "source": [
    "# NEW CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5f6bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81de2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data_points = 2000\n",
    "np.random.seed(42)\n",
    "random_points = np.random.normal(size=data_points)\n",
    "\n",
    "x = random_points[:1000]\n",
    "y = random_points[1000:]\n",
    "df = pd.DataFrame({'x1': x, 'y1': y})\n",
    "\n",
    "def leq(a):\n",
    "    return a\n",
    "    \n",
    "mar = 0.3\n",
    "df1 = df[(df['y1'] > leq(df['x1']) + mar)]\n",
    "df2 = df[(df['y1'] < leq(df['x1']) - mar)] \n",
    "d1 = df1['x1']\n",
    "d2 = df1['y1']\n",
    "d3 = df2['x1']\n",
    "d4 = df2['y1']\n",
    "\n",
    "# Set color based on the condition\n",
    "label = np.where((df['y1'] > leq(df['x1']) + mar) | (df['y1'] < leq(df['x1']) - mar),1,-1)\n",
    "plt.scatter(d1,d2, c='black', marker='.', s=34, label='Class 1')\n",
    "plt.scatter(d3,d4, c='grey', marker='4', s=31, label='Class -1')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f88c48",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class Perceptron: \n",
    "    def __init__(self, learning_rate=0.1):\n",
    "        self.learning_rate=learning_rate\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.sign(np.dot(X, self.w) + self.b)\n",
    "        \n",
    "    def training(self, X, y):\n",
    "        self.w = np.random.rand(X.shape[1])\n",
    "        self.b = 9\n",
    "        iteration = 0\n",
    "        \n",
    "        while not np.all(self.predict(X)==y):\n",
    "            for i in range(X.shape[0]):\n",
    "                prediction = np.dot(X[i],self.w)+self.b\n",
    "                if prediction*y[i]<=0:\n",
    "                    self.w += self.learning_rate*y[i]*X[i]\n",
    "                    self.b += self.learning_rate*y[i]\n",
    "                    \n",
    "                iteration +=1\n",
    "                \n",
    "            return iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710cb16",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training the perceptron with normalized features\n",
    "X_train_normalized = df_normalized[['x1', 'y1']].values\n",
    "y_train = label\n",
    "\n",
    "perceptron = Perceptron(learning_rate=0.1)\n",
    "iterations = perceptron.training(X_train_normalized, y_train)\n",
    "\n",
    "# Plotting the decision boundary\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot for Class 1 and Class -1 points\n",
    "plt.scatter(d1, d2, c='black', marker='.', s=34, label='Class 1')\n",
    "plt.scatter(d3, d4, c='grey', marker='4', s=31, label='Class -1')\n",
    "\n",
    "# Plotting decision boundary\n",
    "x_decision_boundary = np.linspace(X_train_normalized[:, 0].min(), X_train_normalized[:, 0].max(), 100)\n",
    "y_decision_boundary = -(perceptron.w[0] * x_decision_boundary + perceptron.b) / perceptron.w[1]\n",
    "plt.plot(x_decision_boundary, y_decision_boundary, label='Decision Boundary', color='red')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(f'Perceptron Learning Algorithm (Iterations: {iterations})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18857f6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Training the perceptron with normalized features\n",
    "X_train_normalized = df_normalized[['x1', 'y1']].values\n",
    "y_train = label\n",
    "\n",
    "perceptron = Perceptron(learning_rate=0.1)\n",
    "iterations = perceptron.training(X_train_normalized, y_train)\n",
    "\n",
    "# Plotting the decision boundary\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot for Class 1 and Class -1 points\n",
    "plt.scatter(d1, d2, c='black', marker='.', s=34, label='Class 1')\n",
    "plt.scatter(d3, d4, c='grey', marker='4', s=31, label='Class -1')\n",
    "\n",
    "# Plotting decision boundary\n",
    "x_decision_boundary = np.linspace(X_train_normalized[:, 0].min(), X_train_normalized[:, 0].max(), 100)\n",
    "y_decision_boundary = -(perceptron.w[0] * x_decision_boundary + perceptron.b) / perceptron.w[1]\n",
    "plt.plot(x_decision_boundary, y_decision_boundary, label='Decision Boundary', color='red')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(f'Perceptron Learning Algorithm (Iterations: {iterations})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775d97ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a6bc8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def generate_linearly_separable_data(points, gamma):\n",
    "    np.random.seed(42)\n",
    "    x1 = np.random.normal(loc=[3*gamma, 2*gamma], scale=0.5, size=(points, 2))\n",
    "    x2 = np.random.normal(loc=[-2*gamma, -2*gamma], scale=0.5, size=(points, 2))\n",
    "    data = np.vstack((x1, x2))\n",
    "    labels = np.array([1] * points + [-1] * points)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bdb642",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create a dataset with 1000 points and varying levels of separability (gamma)\n",
    "gammas = [0.5, 1.0, 1.5, 2.0, 2.5]\n",
    "datasets = []\n",
    "\n",
    "for gamma in gammas:\n",
    "    data, labels = generate_linearly_separable_data(500, gamma)\n",
    "    datasets.append((data, labels))\n",
    "\n",
    "# Plot the datasets\n",
    "plt.figure(figsize=(12, 9))\n",
    "for i, (data, labels) in enumerate(datasets, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=labels, cmap=plt.cm.Paired, marker='o')\n",
    "    plt.title(f'Dataset with γ = {gammas[i-1]}')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1526f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1, max_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        self.bias = 0\n",
    "        iteration = 0\n",
    "\n",
    "        while iteration < self.max_iterations:\n",
    "            misclassified_points = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                prediction = np.dot(xi, self.weights) + self.bias\n",
    "                if prediction * target <= 0:\n",
    "                    misclassified_points += 1\n",
    "                    self.weights += self.learning_rate * target * xi\n",
    "                    self.bias += self.learning_rate * target\n",
    "\n",
    "            if misclassified_points == 0:\n",
    "                break\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "        return iteration\n",
    "\n",
    "# Train the perceptron on each dataset and plot the results\n",
    "avg_iterations = []\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, (data, labels) in enumerate(datasets, 1):\n",
    "    perceptron = Perceptron()\n",
    "    iterations = perceptron.train(data, labels)\n",
    "    avg_iterations.append(iterations)\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    plt.subplot(2, 3, i)\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=labels, cmap=plt.cm.Paired, marker='o')\n",
    "    plt.title(f'Dataset with γ = {gammas[i-1]} - {iterations} iterations')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    x_decision = np.linspace(data[:, 0].min(), data[:, 0].max(), 100)\n",
    "    y_decision = (-perceptron.weights[0] / perceptron.weights[1]) * x_decision - (perceptron.bias / perceptron.weights[1])\n",
    "    plt.plot(x_decision, y_decision, linestyle='-', color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print average iterations for each level of γ\n",
    "avg_iterations = np.array(avg_iterations)\n",
    "for i, gamma in enumerate(gammas):\n",
    "    print(f'Average iterations for γ = {gamma}: {np.mean(avg_iterations[i::len(gammas)])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9759e053",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c498ff15",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.7",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "julia",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
